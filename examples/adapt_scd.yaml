# training options
init_model_path: experiment/multi_gpu/my_model/models
init_epochs: 90-100
attractor_loss_ratio: 1.0
attractor_encoder_dropout: 0.1
attractor_decoder_dropout: 0.1
context_size: 7
detach_attractor_loss: False
dev_batchsize: 128
encoder_units: 2048
feature_dim: 23
frame_shift: 80
frame_size: 200
use_last_samples: True
gpu: 1
gradclip: 5
hidden_size: 256
input_transform: logmel_meannorm
log_report_batches_num: 100
max_epochs: 100
model_type: TransformerSCDEDA
num_frames: 500
num_speakers: 2
num_workers: 1
optimizer: adam
lr: 2e-5
output_path: experiment/multi_gpu/my_model/callhome_adapt_3
sampling_rate: 8000
seed: 4
subsampling: 10
time_shuffle: True
train_batchsize: 16
transformer_encoder_dropout: 0.1
transformer_encoder_n_heads: 4
transformer_encoder_n_layers: 4
train_data_dir: /home/cymoon/dataset/callhome/data/callhome1_spk2
valid_data_dir: /home/cymoon/dataset/callhome/data/callhome2_spk2
